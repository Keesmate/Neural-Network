import numpy as np
import math
import pandas as pd
import matplotlib.pyplot as plt

# set random seed so that the results stay the same
np.random.seed(42)

''' Coding task 1: Define three characters from your own name (we have chosen the letters K, I and A) '''
# create three letters in 5x5 matrix (Chosen letters are K, I and A)
K = np.array([[0.99, 0.  , 0.  , 0.99, 0.  ],
              [0.99, 0.  , 0.99, 0.  , 0.  ],
              [0.99, 0.99, 0.  , 0.  , 0.  ],
              [0.99, 0.  , 0.99, 0.  , 0.  ],
              [0.99, 0.  , 0.  , 0.99, 0.  ]])

I = np.array([[0.  , 0.99, 0.99, 0.99, 0.  ],
              [0.  , 0.  , 0.99, 0.  , 0.  ],
              [0.  , 0.  , 0.99, 0.  , 0.  ],
              [0.  , 0.  , 0.99, 0.  , 0.  ],
              [0.  , 0.99, 0.99, 0.99, 0.  ]])

A = np.array([[0.  , 0.  , 0.99, 0.  , 0.  ],
              [0.  , 0.99, 0.  , 0.99, 0.  ],
              [0.  , 0.99, 0.99, 0.99, 0.  ],
              [0.  , 0.99, 0.  , 0.99, 0.  ],
              [0.99, 0.  , 0.  , 0.  , 0.99]])


''' Coding task 2: Create four variations for each character '''
##################################
# Variation 1: In these variations, each letter has emphasise on of their lines (left side for K + A, and the middle for I)
#################################
K_emph = np.array([[0.99, 0.  , 0.  , 0.80, 0.  ],
              [0.99, 0.  , 0.80, 0.  , 0.  ],
              [0.99, 0.80, 0.  , 0.  , 0.  ],
              [0.99, 0.  , 0.80, 0.  , 0.  ],
              [0.99, 0.  , 0.  , 0.80, 0.  ]])

I_emph = np.array([[0.  , 0.80, 0.99, 0.80, 0.  ],
              [0.  , 0.  , 0.99, 0.  , 0.  ],
              [0.  , 0.  , 0.99, 0.  , 0.  ],
              [0.  , 0.  , 0.99, 0.  , 0.  ],
              [0.  , 0.80, 0.99, 0.80, 0.  ]])

A_emph = np.array([[0.  , 0.  , 0.99, 0.  , 0.  ],
              [0.  , 0.99, 0.  , 0.80, 0.  ],
              [0.  , 0.99, 0.80, 0.80, 0.  ],
              [0.  , 0.99, 0.  , 0.80, 0.  ],
              [0.99, 0.  , 0.  , 0.  , 0.80]])


#################################
# Variation 2: In these variations, each letter has been blurred using the function blur
#################################

def blur(letter, size=3, high_value_threshold=0.8, blur_factor=0.2):
    ''' this function takes in a letter (5x5 matrix) and applies a blur around high-value pixels
    the high_value_threshold is the value above which pixels are considered "high value"
    and the blur_factor is the amount of weight to give to the blur when adding to output values
    '''

    # create the output letter
    blur_letter = np.copy(letter)

    # create a padding size variable to look in padding_size number of pixels in each direction
    padding_size = size // 2

    # loop through x coordinates of output letter pixels
    for x in range(blur_letter.shape[0]):

        # loop through y coordinates of output letter pixels
        for y in range(blur_letter.shape[1]):

            # get the surrounding region indices, making sure not to go out of range
            x_start = max(x - padding_size, 0)
            x_end = min(x + padding_size + 1, letter.shape[0])
            y_start = max(y - padding_size, 0)
            y_end = min(y + padding_size + 1, letter.shape[1])

            # create current region to average from
            region = letter[x_start:x_end, y_start:y_end]

            # identify high-value pixels in the region (greater than threshold)
            high_value_pixels = region >= high_value_threshold

            # add more weight to high-value pixels, leaving low-value pixels as they are
            weighted_region = np.where(high_value_pixels, region + blur_factor, region)

            # compute the average of the weighted region
            region_average = np.mean(weighted_region)

            # blend original pixel value with blurred region average
            blur_letter[x, y] = (1 - blur_factor) * letter[x, y] + blur_factor * region_average

    return blur_letter

# created blurred letters
K_blur = blur(K)
I_blur = blur(I)
A_blur = blur(A)

#################################
# Variation 3: In these variations, each letter has had noise added to it using the function (add_noise)
#################################
def add_noise(letter, noise_factor=0.1):
    ''' this function adds random noise to an inputted letter matrix
    the noise_factor controls the degree of noise
    '''
    # generate random noise from normal distribution with the same shape as letter
    noise = np.random.normal(0, noise_factor, letter.shape)

    # add noise to the original letter
    noisy_letter = letter + noise

    # if values went over .99, bring them back to .99
    noisy_letter[noisy_letter > 0.99] = 0.99

    return noisy_letter

K_noisy = add_noise(K)
I_noisy = add_noise(I)
A_noisy = add_noise(A)

#################################
# Variation 4: In these variations, each letter has noise and blur add to it
#################################
K_blur_noisy = blur(K_noisy)
I_blur_noisy = blur(I_noisy)
A_blur_noisy = blur(A_noisy)



''' Coding task 3: Make a correlation matrix for your inputs '''
# create lists with created letters
K_variations = [K_emph, K_blur, K_noisy, K_blur_noisy]
I_variations = [I_emph, I_blur, I_noisy, I_blur_noisy]
A_variations = [A_emph, A_blur, A_noisy, A_blur_noisy]
all_letters = K_variations + I_variations + A_variations

# create empty correlation matrix to fill with size of your number of letters in each dimension
correlation_matrix = np.zeros((len(all_letters), len(all_letters)))
using_dot = np.zeros((len(all_letters), len(all_letters)))

# loop thorugh length all_letters
for i in range(len(all_letters)):

    # loop thorugh length all_letters again
    for j in range(len(all_letters)):

        # get current inproduct using matrix multiplication and summing
        correlation_matrix[i, j] = round(np.sum(all_letters[i] * all_letters[j]), 7)
        # using dot product of vectors just for comparison to show that its the same
        using_dot[i,j] = round(np.dot(all_letters[i].ravel(), all_letters[j].ravel()), 7)

np.array_equal(correlation_matrix, using_dot)
# create dataframe in pandas to make it easier to read
letter_labels = ["K_emph", "K_blur", "K_noisy", "K_blur_noisy",
                 "I_emph", "I_blur", "I_noisy", "I_blur_noisy",
                 "A_emph", "A_blur", "A_noisy", "A_blur_noisy"]
correlation_df = pd.DataFrame(correlation_matrix, index=letter_labels, columns=letter_labels)
pd.set_option('display.max_columns', None)

# export dataframe to CSV file for further readability (columns aren't side by side in normal output)
# correlation_df.to_csv("correlation_matrix.csv", index=True)



''' Coding task 4: Create a matrix NN1 to recognise your three characters '''
# create a classifier for each letter which is the average of all four variations
K_classifier = np.round(np.mean(K_variations, axis=0), 3)
I_classifier = np.round(np.mean(I_variations, axis=0), 3)
A_classifier = np.round(np.mean(A_variations, axis=0), 3)

# create neural network in the same way as the lecture slides
classifiers = [K_classifier, I_classifier, A_classifier]
NN = np.vstack([classif.ravel() for classif in classifiers])

''' Coding task 5: Test your matrix on all your inputs and show the scores:
we looped through letter variations and made a grouped bar chart for each letter. we changed which letter was
looped through and saved the corresponding grouped barchart for each letter with the current letter in green
'''
# create labels for the barcharts
K_variation_labels = ["K_emph", "K_blur", "K_noisy", "K_blur_noisy"]
I_variation_labels = ["I_emph", "I_blur", "I_noisy", "I_blur_noisy"]
A_variation_labels = ["A_emph", "A_blur", "A_noisy", "A_blur_noisy"]

# create array to store scores of each letters variation

# loop through each variation in K_variations (changed to I_variations and A_variations for  corresponding barcharts)
# for variation in all_letters:

#     # obtain the inproduct of each combination of variation and classifier
#     variation_activations = [np.sum(variation * classifier) for classifier in NN1]
#     activations.append(variation_activations)

# # convert to an array
# activations = np.array(activations)

# nicer way to do it
activations = np.vstack([NN@variation.ravel() for variation in all_letters])
activations_labels = K_variation_labels + I_variation_labels + A_variation_labels

# prepare settings for the barcharts
N = len(K_variations)
ind = np.arange(N)
width = 0.2

# plotting
for letter in activations_labels[::4]:
    li = activations_labels.index(letter)

    # plot the scores for each variation
    plt.figure(figsize=(8, 6))
    plt.bar(ind - width, activations[li:li+4,0], width, label='K classifier', color='green')
    plt.bar(ind, activations[li:li+4, 1], width, label='I classifier', color='orange')
    plt.bar(ind + width, activations[li:li+4,2], width, label='A classifier', color='red')

    # add labels, title, threshold line and show plot
    plt.ylabel('Activation')
    plt.title(f'Classifier Activations for letter {letter[0]} Variations')
    plt.xticks(ind, activations_labels[li:li+4])
    plt.ylim(top=10)
    plt.axhline(y=5.2, color='black', linestyle='--', linewidth=1, label='Threshold value')
    plt.legend()
    plt.tight_layout()
    plt.savefig(f'{letter[0]}_vars_class.png')

''' 6. Really test your network: make four or more inputs and use NN1 on it. Find multiple inputs (3 or
more) that are not correctly classified. Check what happens if you input all 1's or all zeros? Try to make an
incorrectly classified character by changing only one pixel. Is this possible? Can you do it by only changing
two pixels? Three pixels? '''
# Input all ones:
# array([ 9.384,  8.434, 10.053]) - High values for everything
all_ones = NN @ np.ones(K_emph.shape).ravel()

# Input all zeros
# array([0., 0., 0.]) - Cannot classify as anything, no input
all_zeros = NN @ np.zeros(K_emph.shape).ravel()

# Making incorrectly classified characters by changing 1, 2, 3 pixels in K
print(NN@K_emph.ravel()) # original
K_pixel_change = np.copy(K_emph)

K_pixel_change[0, 0] = 0
print(NN@K_pixel_change.ravel()) # 1 pix
K_pixel_change[:2, 0] = 0
print(NN@K_pixel_change.ravel()) # 2 pix
K_pixel_change[:3, 0] = 0 
print(NN@K_pixel_change.ravel()) # 3 pix
K_pixel_change[:, 0] = 0 # 5 pix
print(NN@K_pixel_change.ravel())

# trying with I now
print(NN@I_blur.ravel()) # original
I_pixel_change = np.copy(I_blur)
I_pixel_change[0, 2] = 0
print(NN@I_pixel_change.ravel()) # 1 pix
I_pixel_change[:2, 2] = 0
print(NN@I_pixel_change.ravel()) # 2 pix
I_pixel_change[:3, 2] = 0 
print(NN@I_pixel_change.ravel()) # 3 pix
I_pixel_change[:, 2] = 0 # 5 pix
print(NN@I_pixel_change.ravel())

# NN gets worse and worse at recognizing K_emph or I_blur but doesnt confuse it for something else, 
# Instead it doesnt classify anything

'''
7. Find multiple inputs (not all zeros) so that NN1 cannot make a decision: it gives exactly equal values for all
characters. Is there a method for finding such inputs? Describe how you can create such counterexamples.
'''
# method = dot product of NN @ vector must return same value for each element
# for multiple inputs this must be the same
# input that is average of classifiers: not EXACTLY same value for each decisino but more or less
    # effectively the same as average of all inputs since classifier is just average of all inputs of one category
average_of_classifier = NN @ np.mean(NN, axis = 0) 
print(average_of_classifier)
mid_value = NN @ np.random.uniform(.45,.55,(25,1))
print(mid_value)
overall_random = NN @ np.random.uniform(.05, .95, (25,1))
print(overall_random)

# WOULD MAKE I'DONT KNOW THRESHOLD SOMETHING BASED ON THE ABOVE VALUES: 
# eg. response of NN to mean of inputs or random generated values

# to find EXACTLY the same values: Null space of differences between NN classifier vectors
# Difference vectors capture the differences / distinctions what make the  vectors unique
# The null space of these difference vectors is the set of vectors that when multiplied by NN matrix are sent to 0
# which can be interpreted as the DIFFERENCES between the vectors becoming 0 
from scipy.linalg import null_space

# Differences between classifiers
diff_ki = K_classifier.ravel() - I_classifier.ravel()
diff_ka = K_classifier.ravel() - A_classifier.ravel()
diff_ia = I_classifier.ravel() - A_classifier.ravel()

# Stack the difference vectors into a matrix
diff_matrix = np.vstack([diff_ki, diff_ka, diff_ia])

# Find the null space of the difference matrix
null_vecs = null_space(diff_matrix)

# Any linear combination of vectors in null space gives equal classifier activations
NN @ null_vecs[:,3]*5
NN @ (null_vecs[:, 2] + null_vecs[:, 6]*6)
NN @ np.mean(null_vecs, axis = 1) * 20