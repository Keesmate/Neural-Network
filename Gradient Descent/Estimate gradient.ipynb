{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "235cb601",
   "metadata": {},
   "source": [
    "# 1. Define your Diff function in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48294501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "random.seed(42)\n",
    "\n",
    "\n",
    "# pick three vectors corresponding to letter of each group members name\n",
    "u = (59, 94)\n",
    "v = (62, 60)\n",
    "w = (10, 40)\n",
    "\n",
    "\n",
    "# define distance function \n",
    "def distance(vector_1, vector_2):\n",
    "    ''' this function takes in two vectors and calculates and returns the distance between them'''\n",
    "    \n",
    "    return math.log(3 + 3 * (vector_1[0] - vector_2[0]) ** 2 + 1.5 * (vector_1[1] - vector_2[1]) ** 2)\n",
    "\n",
    "\n",
    "# define the overall difference function\n",
    "def difference(input_vector):\n",
    "    ''' this function takes in a vector, compares it to the three fixed vectors for our group\n",
    "    and returns the overall difference '''\n",
    "    \n",
    "    return distance(input_vector, u) + distance(input_vector, v) + distance(input_vector, w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f2edaf",
   "metadata": {},
   "source": [
    "# 2. Compute Diff(x) for 20 random points. \n",
    "**What is the average value of Diff?**<br>\n",
    "The average value was 24.91\n",
    "\n",
    "**What is the lowest and highest value you found?**<br>\n",
    "Lowest value was 21.63 and the highest was 27.21\n",
    "\n",
    "**Is random search a good way to minimize this function?**<br>\n",
    "No. Random search literally just gives you random points that you can then test the value of. There is no learning from the results of previously tried points and the time to get to a relatively good solution could take a very long time. There is no order and you are not \"approaching\" the minimal value, you are hoping that you happen to get a value that is close to the minimum by pure chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccd21aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference: 24.913858638146543\n",
      "Maximum value: 27.214040207685674\n",
      "Minimum value: 21.63492481784673\n"
     ]
    }
   ],
   "source": [
    "# randomly generate 20 points within the range\n",
    "random_points = [(random.uniform(0, 100), random.uniform(0, 100)) for _ in range(20)]\n",
    "\n",
    "# obtain the difference values for each of the 20 randomly generated points\n",
    "diff_values = [difference(point) for point in random_points]\n",
    "\n",
    "# obtain and print the average, highest and lowest value\n",
    "average_diff = np.mean(diff_values)\n",
    "max_diff = np.max(diff_values)\n",
    "min_diff = np.min(diff_values)\n",
    "print(f'Average difference: {average_diff}\\nMaximum value: {max_diff}\\nMinimum value: {min_diff}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c7446e",
   "metadata": {},
   "source": [
    "# 3. Set xzero=(50,50). Compute Diff(x)=Diff(50,50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ed0a023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.93451831163977\n"
     ]
    }
   ],
   "source": [
    "# create xzero and test with the difference function\n",
    "xzero = (50, 50)\n",
    "xzero_diff = difference(xzero)\n",
    "print(xzero_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5543af6d",
   "metadata": {},
   "source": [
    "# 4. Create a function to compute and print the gradient of Diff by using a small delta=0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d09ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that calculates the gradient of the difference\n",
    "def gradient_diff(input_vector, delta = 0.001):\n",
    "    ''' this function takes in an input_vector and calculates its gradient in the \n",
    "    difference function '''\n",
    "    \n",
    "    # alter x_1 by delta then calculate the first partial derivative (gradient of x1)\n",
    "    altered_x1_vector = (input_vector[0] + delta, input_vector[1])\n",
    "    x1_gradient = (difference(altered_x1_vector) - difference(input_vector)) / delta\n",
    "    \n",
    "    # alter x_2 by delta then calculate the second partial derivative (gradient of x2)\n",
    "    altered_x2_vector = (input_vector[0], input_vector[1]  + delta)\n",
    "    x2_gradient = (difference(altered_x2_vector) - difference(input_vector)) / delta\n",
    "\n",
    "    return (x1_gradient, x2_gradient)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5c857",
   "metadata": {},
   "source": [
    "# 5. Use this function to print the gradient at (0,0), (100,0), (0,100) and (100,100). \n",
    "**Based on these values, is it likely that the minimum of the function is inside this area? And the maximum?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae9a0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fea926f1",
   "metadata": {},
   "source": [
    "# 6. Define xzero=(50,50) and stepsize=1.0. \n",
    "**Make a function to compute xnext by taking e a small step into the opposite direction of the gradient, so that diff decreases. E.g. if the gradient is (0.4,0.6), do xnext=(oldx1-0.4*stepsize,oldx2-0.6*stepsize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaba8e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b56b0678",
   "metadata": {},
   "source": [
    "# 7. Repeat this multiple times (make a function to do this automatically) and print x and Diff(x) at each step. \n",
    "**You may need to adjust stepsize if you overshoot or are not moving at all. Try to reach a local minimum.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7cd0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cf9db90",
   "metadata": {},
   "source": [
    "# 8. Repeat step 7 with starting points (0,0) and (100,100). \n",
    "**Do you always end up at the same point?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6973f319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f596b5d7",
   "metadata": {},
   "source": [
    "# 9. Make the nicest possible chart using mathplotlib that shows what the Diff function looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f3dec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec21d61d",
   "metadata": {},
   "source": [
    "# 10. Show the gradient field as well in a chart. \n",
    "**Use a new plot or add the gradient to the original plot.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5b399",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
